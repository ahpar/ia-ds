{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto #3 - Meu primeiro projeto de IA\n",
    "\n",
    "Antes de começar, leia as [Instruções](https://github.com/thvmm/pos-ds-ia/blob/master/projeto_3/README.md) e os [Critérios de Avaliação](https://github.com/thvmm/pos-ds-ia/blob/master/projeto_3/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) **(5%)** Qual a base escolhida e qual seu interesse nela (podem ser mais de uma)? Descrição básica do conjunto de dados escolhido pelo aluno (1 parágrafo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Indique o link da base no Kaggle e explique em um parágrafo curto por que essa base é interessante para você. Quais são as características básicas da base?*\n",
    "\n",
    "Ex: Estou trabalhando com o histório de vendas de um varejo e uma outra base do mesmo varejista das suas campanhas de marketing realizadas em veiculos de comunicação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As bases de dados selecionadas para esse estudo advêm da combinação dos dados de [perfilagem geofísica] (https://en.wikipedia.org/wiki/Well_logging) de 5 furos de sondagem de exploração mineral (fase de pesquisa) com dados da descrição geológica de [testemunhos de sondagem] (https://en.wikipedia.org/wiki/Core_sample). No contexto da mineração esses dados em conjunto as análises geoquímica com compõe a melhor forma de estudarmos e entendermos como a Terra está organizada em subsuperfície e, consequentemente, como os recursos minerais podem ser explorados e explotados de forma sustentável.\n",
    "\n",
    "A base de dados da perfilagem geofísica pode ser descrita de forma sismples como a medida em função da profundidades das propriedades físicas dos materiais geológicos que estão em subsuperfície ( e.g. densidade, susceptibilidade magnética, resistividade elétrica, radiação etc).\n",
    "\n",
    "A base de dados da descrição geológica de testemunhos de sondagem consiste na descrição visual das caracteristicas geológicas dos materiais amostrados pelo furo de sondagem (e.g textura, coloração, mineralogia, classificação em [litologias] (https://en.wikipedia.org/wiki/Lithology) etc). \n",
    "\n",
    "Como os dados são de propriedade da Vale S.A. informações sensíveis como localização e nome do poço foram suprimidas do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) **(5%)** Que tipo de problema podemos solucionar com ela? Liste ao menos 3 hipóteses sobre seus dados, caso sua base seja muito restrita converse com os professores antes de seguir.\n",
    "- Quais são suas hipoteses sobre os dados? O que vc espera descobrir com esse estudo?\n",
    "\n",
    "Ex: Hipoteses válidas seriam:\n",
    "- As pessoas fazem mais compras nos dias utéis ou finais de semana?\n",
    "- Existe diferença entre o padrão de compra de segunda ou terça feira?\n",
    "- O horário de pico influencia no padrão de compra dos clientes?\n",
    "- Quais produtos são comprados mais juntos? Existe diferença se observarmos a idade do cliente?\n",
    "- Qual o efeito de uma campanha de marketing nas vendas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas hipoteses são:\n",
    "* Existe diferença significativas de propriedade fisica para os litotipos observados?\n",
    "* Há alguma variação nos litotipos observados/amostrados pelos diferentes furos?\n",
    "* Há alguma relação de dependência dos diferentes litotipos com a profundidade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) **(20%)** Preparação de dados\n",
    "\n",
    "Hora de deixar a base perfeita para se trabalhar. Limpe os dados, integre com outras fontes e transforme-o para ficar pronto para se trabalhar! No fim, mostre um antes e depois de seu dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemente sua análise aqui. Use mais blocos se achar que ficará mais organizado.\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "#Funções úteis\n",
    "\n",
    "# Função p/ importar o CLV da descrição para df da perfilagem \n",
    "def get_desc(log,desc):\n",
    "  \n",
    "    furos = list(desc['Furo'].unique()) #lista dos furos descritos\n",
    "    li = []\n",
    "   \n",
    "    for furo in furos:   \n",
    "        \n",
    "        df_log_tmp = log[log['FURO'] == furo]\n",
    "        df_desc_tmp = desc[desc['Furo'] == furo]\n",
    "       \n",
    "        for i in df_log_tmp.index:              #percorre todas instancias do df_log\n",
    "            for j in df_desc_tmp.index:         #percorre todos os intervalos de descrição\n",
    "                if df_desc_tmp.get_value(j,'De') <= df_log_tmp.get_value(i,'DEPT') < df_desc_tmp.get_value(j,'Ate'):\n",
    "                    df_log_tmp.set_value(i,'CLV',df_desc.get_value(j,'CLV'))     #atualiza o CLV no df_log a partir do CLV da descrição\n",
    "        \n",
    "        li.append(df_log_tmp)\n",
    "   \n",
    "    df = pd.concat(li, ignore_index=True)\n",
    "   \n",
    "    return df \n",
    "\n",
    "def missing_percentage(df):\n",
    "    total = df.isnull().sum()\n",
    "    percent = round(df.isnull().mean()*100,2)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n",
    "    \n",
    "#PLOTS\n",
    "\n",
    "def make_clv_log_plot(df, curves, clv_colors):\n",
    "\n",
    "    logs = df.sort_values(by='DEPT')             #ordena o furo por profundidade\n",
    "    \n",
    "    cmap_clv = colors.ListedColormap(clv_colors[0:len(clv_colors)], 'indexed')\n",
    "\n",
    "    ztop=logs.DEPT.min(); zbot=logs.DEPT.max()\n",
    "\n",
    "    cluster=np.repeat(np.expand_dims(logs['CLV_code'].values,1), 100, 1)\n",
    "\n",
    "    ncurves = len(curves)\n",
    "\n",
    "    f, ax = plt.subplots(nrows=1, ncols=ncurves+1, figsize=(ncurves * 2, 12))\n",
    "\n",
    "    for i, curve in enumerate(curves):\n",
    "        ax[i].plot(logs[curve], logs['DEPT'], '-', color='black')\n",
    "\n",
    "    im=ax[ncurves].imshow(cluster, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_clv,vmin=1,vmax=17)\n",
    "\n",
    "    divider = make_axes_locatable(ax[ncurves])\n",
    "    cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label((5*' ').join(['AT','CG', 'MD', 'MSD','MS',\n",
    "                                    'JPC', 'JPF', 'HF', 'RIF',\n",
    "                                    'HGOF', 'SR', 'HCTF', 'RIS',\n",
    "                                    'JPS', 'RIC', 'HC', 'RCF']))\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "\n",
    "    for i in range(len(ax)-1):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "\n",
    "    for i, curve in enumerate(curves):\n",
    "        ax[i].set_xlabel(curve)\n",
    "        ax[i].set_xlim(logs[curve].min(), logs[curve].max())   \n",
    "    ax[ncurves].set_xlabel('CLV')\n",
    "\n",
    "    for i in range(len(ax)-1):\n",
    "        ax[i+1].set_yticklabels([]); \n",
    "    \n",
    "    ax[ncurves].set_xticklabels([])\n",
    "    f.suptitle('Furo: %s'%logs.iloc[0]['FURO'], fontsize=14,y=0.94)\n",
    "\n",
    "\n",
    "def compare_clv_log_plot(df, curves, prediction, clv_colors):\n",
    "\n",
    "    logs = df.sort_values(by='DEPT')             #ordena o furo por profundidade\n",
    "    \n",
    "    cmap_clv = colors.ListedColormap(clv_colors[0:len(clv_colors)], 'indexed')\n",
    "\n",
    "    ztop=logs.DEPT.min(); zbot=logs.DEPT.max()\n",
    "\n",
    "    cluster1=np.repeat(np.expand_dims(logs['CLV_code'].values,1), 100, 1)\n",
    "    cluster2=np.repeat(np.expand_dims(logs[prediction+'_code'].values,1), 100, 1)\n",
    "   \n",
    "    ncurves = len(curves)\n",
    "\n",
    "    f, ax = plt.subplots(nrows=1, ncols=ncurves+2, figsize=(ncurves * 2, 12))\n",
    "\n",
    "    for i, curve in enumerate(curves):\n",
    "        ax[i].plot(logs[curve], logs['DEPT'], '-', color='black')\n",
    "\n",
    "    im1 = ax[ncurves].imshow(cluster1, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_clv,vmin=1,vmax=17)\n",
    "    im2 = ax[ncurves+1].imshow(cluster2, interpolation='none', aspect='auto',                           cmap=cmap_clv,vmin=1,vmax=14)\n",
    "\n",
    "    divider = make_axes_locatable(ax[ncurves+1])\n",
    "    cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im1, cax=cax)\n",
    "    cbar.set_label((5*' ').join(['AT','CG', 'MD', 'MSD','MS',\n",
    "                                    'JPC', 'JPF', 'HF', 'RIF',\n",
    "                                    'HGOF', 'SR', 'HCTF', 'RIS',\n",
    "                                    'JPS', 'RIC', 'HC', 'RCF']))\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "\n",
    "    for i in range(len(ax)-2):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "\n",
    "    for i, curve in enumerate(curves):\n",
    "        ax[i].set_xlabel(curve)\n",
    "        ax[i].set_xlim(logs[curve].min(), logs[curve].max())   \n",
    "    ax[ncurves].set_xlabel('CLV')\n",
    "    ax[ncurves+1].set_xlabel(prediction)\n",
    "\n",
    "    for i in range(len(ax)-1):\n",
    "        ax[i+1].set_yticklabels([]); \n",
    "    \n",
    "    ax[ncurves].set_xticklabels([])\n",
    "    ax[ncurves+1].set_xticklabels([])\n",
    "    f.suptitle('Furo: %s'%logs.iloc[0]['FURO'], fontsize=14,y=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação da base de dados de descrição geológica. Os litotipos são a feature CLV\n",
    "df_desc = pd.read_csv('./data/desc.csv')\n",
    "df_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removendo whitespaces no feature Furo\n",
    "df_desc['Furo'] = df_desc['Furo'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação da base de dados de perfilagem geofísica\n",
    "df_log = pd.read_csv('./data/log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conferindo os furos em ambas bases de dados\n",
    "df_desc['Furo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log['FURO'].unique() # furos perfilados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os furos perfilados foram descritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integração das bases de dados de perfilagem geofísica e descrição geológica - Captura do litotipo (CLV) descrito para o intervalo em todas as profundidade de medidas da perfilagem geofísica\n",
    "df = get_desc(df_log,df_desc)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# salvar em um arquivo CSV\n",
    "# df.to_csv('./data/data.csv', index = False)\n",
    "# df = pd.read_csv('./data/data.csv')\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição da base e suas variáveis\n",
    "\n",
    "Mnemonic|Unit|Description|Variable Class\n",
    ":--------:|:----:|:-----------|:---\n",
    "BIT| MM|Bit size|Discrete\n",
    "CADE|MM|Caliper from DD3|Continuous\n",
    "CCLF|CPS|Casing Collar Locator|Continuous\n",
    "CCO1|MM|3-Arm Caliper CO1-GC2|Continuous\n",
    "CO1C|CPS|Caliper Raw|Continuous\n",
    "DD3B|CPS|Short Spaced Density Raw|Continuous\n",
    "DD3C|CPS|Caliper Raw|Continuous\n",
    "DD3G|CPS|Gamma Ray Raw |Continuous\n",
    "DD3L|CPS|Long Spaced Density Raw|Continuous\n",
    "DENB|G/C3|Density Short Spaced|Continuous\n",
    "DENL|G/C3|Density Long Spaced|Continuous\n",
    "DEPT|M|Logged depth|Continuous\n",
    "DNBO|G/C3|Density Short Spaced - Corrected|Continuous\n",
    "DNLO|G/C3|Density Long Spaced - Corrected|Continuous\n",
    "FE1|-|-|Continuous\n",
    "FE2|-|-|Continuous\n",
    "GC1G|CPS|Gamma Ray Raw |Continuous\n",
    "GRC1|GAPI|Gamma Ray from GC1-GC2|Continuous\n",
    "GRDE|API|Gamma Ray from DD3|Continuous\n",
    "GRDO|API|Gamma Ray from DD3 - Corrected|Continuous\n",
    "GTMP|DEGC|Borehole Temperature|Continuous\n",
    "MSS4|SI|Magnetic Susceptbility|Continuous\n",
    "MSUS|SI|Magnetic Susceptbility|Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de valores ausentes\n",
    "import missingno as msno\n",
    "for furo in df.FURO.unique():\n",
    "    msno.matrix(df[df['FURO']== furo],figsize = (12,6))\n",
    "    plt.title('%s'%furo, fontsize = 20)\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de features - Ausentes > 10% (DNLO, FE1, FE2, MSS4 E MSUS) e Conhecimento a priori (BIT, CADE e CCLF) \n",
    "df_selected = df[['FURO', 'DEPT', 'CLV','CCO1', 'CO1C', 'DD3B', 'DD3C', 'DD3G', 'DD3L', 'DENB', 'DENL', 'DNBO', 'GC1G', 'GRC1', 'GRDE', 'GRDO', 'GTMP']]\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover intervalos sem descrição geológica - Litotipos (CLV)\n",
    "df_selected.dropna(subset=['CLV'], axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar dicionário para os Litotipos (CLV)\n",
    "clvDict = {}\n",
    "i = 1\n",
    "for clv in df_selected.CLV.unique():\n",
    "    clvDict[clv] = i\n",
    "    i+=1\n",
    "#criar codigo numérico pra CLV\n",
    "\n",
    "df_selected['CLV_code'] = df_selected.CLV\n",
    "df_selected = df_selected.replace({\"CLV_code\": clvDict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clvDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sumário - Estatística Descritiva Categoricas - Original\n",
    "df.describe(include = [object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário - Estatística Descritiva Categoricas - Prep\n",
    "df_selected.describe(include = [object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário - Estatística Descritiva numéricas - Original\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumário - Estatística Descritiva numéricas - Prep\n",
    "df_selected.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) **(30%)** Análise\n",
    "\n",
    "Com seu dado pronto, é hora de fazer a parte mais legal: investigar e responder nossas hipoteses. Elas se confirmam? Em quais cenários? Existe alguma forma de perceber isso no mundo real? Dica: Abuse das técnicas de visualização.\n",
    "\n",
    "Ex: Ainda no contexto dos exemplos do item 2). Ao investigar a hipotese relacionada ao padrão de compra, percebi que em todos os meses existia uma diferença entre dia util e final de semana. Porém notei que Fevereiro possui um comportamento diferente, o que poderia explicar? Talvez o carnaval e seus feriados.\n",
    "\n",
    "Ex2: Talvez eu descubra que alguns finais de semana possuam um comportamento diferente dos dias de semana e outros não. Por que não são todos? Nessa investigação você pode acabar descobrindo que os finais de semana que são diferentes, coincidem no fato de serem os primeiros dias utéis, o que pode remeter ao fato de boa parte das empresas realizarem pagamentos nessa parte do mês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição dos litotipos\n",
    "sns.catplot(x=\"CLV\", kind=\"count\", data=df_selected, height=5, aspect=2.5 )\n",
    "plt.xticks(rotation = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se um claro desbalanceamento nos litotipos amostrados pelas campanhas de sondagem geológica. Litotipos como HF, JPC e MD em conjunto representam mais de 70% das amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição dos litotipos por furo\n",
    "sns.catplot(x = \"FURO\", hue = \"CLV\", kind = \"count\", data = df_selected, height = 5, aspect = 2.5)\n",
    "plt.xticks(rotation = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa-se também que não há semelhança na distribuição dos litotipos amostrados pelos diferentes furos. Por exemplo o furo SSD-FD01006 apresenta grande variabilidade de litotipos amostrados quando comparado com o furo SSF-FD00995. Ou seja, em um área de prospecção mineral as populações de litotipos observados variam significativamente com a posição dos furos. Por exemplo, o litotipo JPS possui um numeto pequeno de amostras, sendo observado apenas nos furos  final 998 e 995. Esse último intercepta em praticamente toda sua extensão o litotipo JPC. Os litotipos MS, MSD e MD são amostrado quase que exclusivamente pelo furo final 1038."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caracterização das propriedades físicas por CLV\n",
    "\n",
    "for log in df_selected.select_dtypes(include=['int64', 'float64']).drop(['DEPT', 'CLV_code'], axis = 1).columns:  #features numéricos exceto DEPT e CLV_code\n",
    "    sns.boxplot(x = 'CLV', y = log, data = df_selected)\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretando-se os box-plots acima percebe-se que os logs de perfilagens geofísica que possuem distribuições bem-comportada, ou seja, não apresetam muitos outlier, baixa assimetria e variância, individualizando assim os respectivos litotipos (CLV) são: CCO1, DD3B, DENB, DNBO, GRC1, GTMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tendência central das distribuições das propriedades físcas por Litotipo (CLV)\n",
    "df_selected.drop(['CO1C', 'DD3C', 'DD3G', 'DD3L', 'DENL', \n",
    "                    'GC1G', 'GRDE', 'GRDO','DEPT', 'CLV_code'], axis = 1).groupby('CLV').agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com relação as aos valores médios e medianas das diferentes propriedades físicas por litotipo pode-se destacar:\n",
    "* HF e JPC apresentam sistematicamente valores de densidade (DD3B, DENB e DNBO) mais elevados, bem como menores contagens de radiação gamma (GRC1)\n",
    "* AT aprensetam maiores diâmetros no Caliper (CO1C)\n",
    "* RCF e RIC apresentam os maiores valores médios e medianas para contagens de radiação gamma (GRC1)\n",
    "* MD, MSD e RIF apresentam os maiores valores médios de temperatura (GTMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualização conjunta dos logs da perfilagem e do CLV - Avaliação visual do comportamento dos logs de perfilagem\n",
    "\n",
    "#Color dict\n",
    "clv_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "                '#1B4F72','#2E86C1', '#AED6F1', '#A569BD',\n",
    "                '#196F3D','#2E28D1', '#000000', '#A599FD',\n",
    "                '#F4D20F','#14D20F','#F5D70F','#C1D80F','#A4D20F']\n",
    "\n",
    "clv_labels = ['AT','CG', 'MD', 'MSD', 'MS',\n",
    "            'JPC', 'JPF', 'HF', 'RIF', \n",
    "            'HGOF', 'SR', 'HCTF', 'RIS',\n",
    "             'JPS', 'RIC', 'HC', 'RCF']\n",
    "\n",
    "#dicionario p/ mapear as cores a lito (CLV)\n",
    "clv_color_map = {}\n",
    "for ind, label in enumerate(clv_labels):\n",
    "    clv_color_map[label] = clv_colors[ind]\n",
    "\n",
    "curves = df_selected.select_dtypes(include=['int64', 'float64']).drop(['DEPT', 'CLV_code'], axis = 1).columns\n",
    "\n",
    "for furo in df_selected['FURO'].unique():\n",
    "    make_clv_log_plot(df_selected[df_selected['FURO']==furo], curves, clv_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Modelagem 30%\n",
    "\n",
    "Agora você terá mais uma oportunidade de mostrar o que você aprendeu durante o módulo 2 quanto a modelagem de dados e criação de modelos. Utilizando os dados preparados na seção 1 e após a análise feita na seção 2 você deverá:\n",
    "1. **Defina um problema de regressão ou classificação que envolva uma variável dos seus dados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***---> Comente brevemente sua decisão aqui.***\n",
    "Será realizado o problema de classificação dos litotipos (CLV) a partir dos dados de perfilagem geofísica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Realize ao menos 2 técnicas de processamento e seleção de features.**\n",
    "    * Isto inclui, normalização, PCA, e técnicas de seleção de features como information gain. Seja criativo pois está parte é crucial para seu modelo. Você pode escolhar manualmente as features desde que seja justificada na seção 2 (parte de Análise).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A avaliação visual do comportamento dos diversos logs de perfilagem juntamente com o a descrição do furo permite:\n",
    "* observar que o único litotipo que tem uma dependencia clara com a profunidade é AT, ocorrendo sistemetaticamente nos primeiros metros de cada furo;\n",
    "* Não há necessidade de computar se computar métricas de dependencia (correlação/covariancia) para observar difersor logs apresentam comportamento bastante semelhantes, ou seja, são redundantes.\n",
    "\n",
    "Dessa forma, combinando-se com a avaliação realizada sobre os box-plots, os logs que serão utilizados como features são: **CCO1, DENB, GRC1 e GTMP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_selected.drop(['CO1C', 'DD3C', 'DD3B', 'DNBO', 'DD3G', 'DD3L', 'DENL', 'GC1G', 'GRDE', 'GRDO'], axis = 1)\n",
    "data.dropna(axis = 0, how = 'any', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for furo in data['FURO'].unique():\n",
    "    make_clv_log_plot(data[data['FURO']==furo], ['CCO1', 'DENB', 'GRC1', 'GTMP'], clv_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Defina uma métrica para avaliar o seu modelo.**\n",
    "    * Por exemplo, você pode utilizar MAE (Mean Absolute Error) para um problema de regressão. Ou, F1-Score para um problema de classificação. Há varias métricas, então escolha sabiamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***---> Comente brevemente sua decisão aqui.***\n",
    "\n",
    "A métrica utilizada será a F1-Score, por ser tratar de um problema de classificação com sujeito a grande influência de verdadeiros negativos, o que impactaria diretamente na acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Divida seus dados em 2 conjuntos. Um de treino e outro conjunto de teste.**\n",
    "    * Treine e otimize seu modelo no conjunto de treino e apenas use o conjunto de teste para apresentar os resultados finais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação de um dos furos para teste cego do modelo de classificação (foi escolhido pela minha sobrinha) =)\n",
    "\n",
    "test_data = data[data['FURO'] == 'SSD-FD00998']\n",
    "training_data = data[data['FURO'] != 'SSD-FD00998']\n",
    "# blind_test_data.dtypes\n",
    "test_data['FURO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data.dtypes\n",
    "training_data['FURO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data.drop(['DEPT', 'FURO', 'CLV', 'CLV_code'], axis = 1)\n",
    "y_train = training_data['CLV']\n",
    "X_test = test_data.drop(['DEPT', 'FURO', 'CLV', 'CLV_code'], axis = 1)\n",
    "y_test = test_data['CLV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.CLV.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Treine um ou mais modelos de ML para o seu problema.**\n",
    "    * Escolha 1 ou mais tipos de classificadores ou regressores dependendo do seu problema.\n",
    "    * Por exemplo, TreeClassifier para um problema de classificação. \n",
    "    * Use cross-validation e outras técnicas como GridSearch e ou RandomizedSearch para encontrar os melhores parametros para o seu modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "## Grade de hiperparâmetros - Random Search\n",
    "\n",
    "# num de arvores na floresta\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 10)]\n",
    "# num de featrures consideradas em cada split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# num max de niveis em uma arvore\n",
    "max_depth = [int(x) for x in np.linspace(5, 50, num = 10)]\n",
    "max_depth.append(None)\n",
    "# num min de samples para split de node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# num min de sample em cada folha/node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# metodo de seleção de amostras para treinar cada arvore\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Treinamento Random Search\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose = 10, random_state = 42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros ajustados\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "y_rf = best_random.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"F1-Score Avg (Random Search): %0.2f\" % metrics.f1_score(y_test, y_rf, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenar predicoes do RF  na base de test\n",
    "\n",
    "test_data['RF'] = y_rf\n",
    "test_data['RF_code'] = y_rf\n",
    "test_data = test_data.replace({'RF_code': clvDict})\n",
    "test_data['RF_code'] = test_data['RF_code'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Apresente (com visualizações) os resultados do seu modelo mostrando que ele é melhor do que um baseline não aleatório.**\n",
    "    * Para o baseline, você pode escolher um modelo bem trivial mas não aleatório. Por exemplo, para um problema de classificação um baseline pode ser a classe mais presente caso o conjunto de dados seja desbalanceado.  Um modelo mais simples também pode ser utilizado como baseline, por exemplo, você escolheu um Random Forest Classifier, e comparou os resultados um Logistic Regression. Você pode até mesmo escolher um modelo de AutoML(como TPOT) como Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "rf_base = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "rf_base.fit(X_train, y_train)\n",
    "\n",
    "y_base = rf_base.predict(X_test)\n",
    "\n",
    "print(\"F1-Score (Baseline): %0.2f\" % metrics.f1_score(y_test, y_base, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Armazenar predicoes do baseline na base de test\n",
    "test_data['RF_base'] = y_base\n",
    "test_data['RF_base_code'] = y_base\n",
    "test_data = test_data.replace({'RF_base_code': clvDict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['RF_base_code'] = test_data['RF_base_code'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicoes do modelo RF\n",
    "compare_clv_log_plot(test_data, ['CCO1', 'DENB', 'GRC1', 'GTMP'], 'RF', clv_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar predicoes do modelo baseline\n",
    "compare_clv_log_plot(test_data, ['CCO1', 'DENB', 'GRC1', 'GTMP'], 'RF_base', clv_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Conclusões **10%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Partindo das suas hipoteses e investigações, o que você consegue concluir? Suas hipoteses se concretizaram?*\n",
    "\n",
    "Seguem algumas conclusões:\n",
    "\n",
    "* Os litotipos apresentam varições de propriedades físicas, de modo geral\n",
    "    * HF e JPC apresentam sistematicamente valores de densidade (DD3B, DENB e DNBO) mais elevados, bem como menores contagens de radiação gamma (GRC1)\n",
    "    * AT aprensetam maiores diâmetros no Caliper (CO1C)\n",
    "    * RCF e RIC apresentam os maiores valores médios e medianas para contagens de radiação gamma (GRC1)\n",
    "    * MD, MSD e RIF apresentam os maiores valores médios de temperatura (GTMP)\n",
    "\n",
    "* Observa-se também que não há semelhança na distribuição dos litotipos amostrados pelos diferentes furos. Por exemplo o furo SSD-FD01006 apresenta grande variabilidade de litotipos amostrados quando comparado com o furo SSF-FD00995. Ou seja, em um área de prospecção mineral as populações de litotipos observados variam significativamente com a posição dos furos. Por exemplo, o litotipo JPS possui um numeto pequeno de amostras, sendo observado apenas nos furos final 998 e 995. Esse último intercepta em praticamente toda sua extensão o litotipo JPC. Os litotipos MS, MSD e MD são amostrado quase que exclusivamente pelo furo final 1038.\n",
    "\n",
    "* Com exceção do litotipo AT, não existe relação de dependência entre os litotipos e a profundidade \n",
    " \n",
    " Com relação a classificação dos litotipos a partir dos dados de perfilagem geofisica:\n",
    "* Random Forest com hiperparâmetros otimizados (Random Search) mostra um aumento significativo de 25% na métrica de validação (F1-Score) com relação  desempenho do Random Forest - Baseline\n",
    "* A validação visual mostra que apesar dos contatos entre litotipos estarem bem posicionados, apesar da grande quantidade de falsos positivos\n",
    "* Por ser tratar de um problema com um grande número de classes penso que seria necessário expadir o número de features para obter melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ai': conda)",
   "language": "python",
   "name": "python37364bitaiconda1e3a5215f9754c9b88b7d7c6990eacaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}